<!DOCTYPE html><html lang="en-us" >


<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  
  
  
    <meta name="generator" content="Wowchemy 5.3.0 for Hugo" />
  

  
  









  




  
  
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin />
  

  
  
  
    
      
      <link rel="preload" as="style" href="https://fonts.googleapis.com/css2?family=Cutive+Mono&family=Lora:wght@400;700&family=Roboto:wght@400;700&display=swap&display=swap">
      <link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Cutive+Mono&family=Lora:wght@400;700&family=Roboto:wght@400;700&display=swap&display=swap" media="print" onload="this.media='all'">
    
  

  
  
  
  
  
    
    
    
  
  

  <meta name="author" content="Yung-Fong Hsu" />

  
  
  
    
  
  <meta name="description" content="Making appropriate decisions involves the ability to update information of alternatives from previous experiences. In particular, the updated reward prediction error (RPE) – a discrepancy between the predicted and the actual rewards, is regarded as being encoded by dopamine neurons. Two issues about RPE were discussed in this thesis. First, dysfunction of RPE might link abnormal dopamine systems and therefore the formation of psychotic symptoms (i.e., hallucination and delusion) in schizophrenia (SZ). To examine this hypothesis, we tested SZ patients and healthy controls using a feedback-based “dynamic rewarding task,” in which the subject was required to choose between two different reward options that were alternated in a block fashion. We fit the experimental data with a (standard) reinforcement learning (RL) model using the Bayesian estimation approach. Model-fitting results revealed that SZ patients update their values more rapidly and have more exploratory decisions. We also found that the degree of exploration increases with the severity of the psychotic symptoms. These findings support the hypothesis that abnormal RPE processes correlate with aberrant dopaminergic activities and subjective psychotic experiences. Second, since an individual’s heritable trait might predispose her/his decision-making behavior, we conducted a Tridimensional Personality Questionnaire on subjects to investigate the correlation between personality traits and the estimated parameters in the RL model. Results showed that college students with higher novelty seeking scores have lower value-updating rates, and those with higher reward dependence scores have higher degree of explorations. Moreover, gender differences were found in the task performance. However, no similar patterns were found in SZ patients. Finally, we briefly discussed two modeling issues that are yet to be resolved. The first concerns the negative correlation between the learning rate parameter and the perseveration parameter in the RL model. The second concerns the issue of scale invariance with regard to the perseveration parameter in the RL model. 動物與人在不確定性環境中決策皆需經由試誤學習才能學習到環境的規則，對環境形成預期並依此作為未來決策的依據。根據增強學習理論的假設，預期的更新發生於預期與實際經驗之間有落差時，該落差被稱為酬賞預測誤差（reward prediction error, RPE）。當研究發現多巴胺細胞能夠記錄RPE訊號，RPE在神經科學的研究開始興起。本研究包含兩個議題，分別探討（i）精神分裂症病人（schizophrenia, SZ）的精神病症狀與RPE之關係，（ii）個體在性格上的差異是否影響RPE的處理歷程。首先，有學者認為多巴胺系統異常導致RPE處理錯誤是SZ病人產生精神病症狀（例如：幻覺與妄想）的原因。為檢驗該假設，本研究讓SZ病人進行以兩選項之機率學習的回饋性決策—動態酬賞作業，在作業中得到酬賞機率大的選項每過一段時間會改變，而且該改變不會告知受試者。本研究使用增強學習模型來分析資料，參數估計使用貝氏估計法。研究發現SZ病人更新預期的速度比較快且有較多探索性決策。此外，隨著病人的精神病症狀越嚴重，則會有越多的探索性決策。這些研究結果與假設相符。研究的第二部份分析Cloninger之三向度性格量表各向度得分與動態酬賞作業表現的相關，結果發現一般大學生在動態酬賞作業的表現存在性別差異，而且新奇追求傾向越高者其更新預期的速度越慢，酬賞依賴傾向越高者其探索性決策越多。然而，在SZ病人並無發現類似的結果。另外，本研究也約略討論增強學習模型的參數性質，包括參數間的相關性與單位不變性。" />

  
  <link rel="alternate" hreflang="en-us" href="https://hsulab.psy.ntu.edu.tw/publication/content/publication/li-2012/" />

  
  
  
    <meta name="theme-color" content="#C2A981" />
  

  
  
    
    <script src="/js/mathjax-config.js"></script>
  

  

  <link rel="stylesheet" href="/css/vendor-bundle.min.f1ecf783c14edc00c9320c205831ad8e.css" media="print" onload="this.media='all'">

  
  
  
    
    
      <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha512-W0xM4mr6dEP9nREo7Z9z+9X70wytKvMGeDsj7ps2+xg5QPrEBXC8tAW1IFnzjR6eoJ90JmCnFzerQJTLzIEHjA==" crossorigin="anonymous" media="print" onload="this.media='all'">
    

    
    
    
    
      
      
    
    
    

    
    
    
      
    
    
      
      
        
          <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/highlightjs/cdn-release@10.2.1/build/styles/github.min.css" crossorigin="anonymous" title="hl-light" media="print" onload="this.media='all'">
          <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/highlightjs/cdn-release@10.2.1/build/styles/dracula.min.css" crossorigin="anonymous" title="hl-dark" media="print" onload="this.media='all'" disabled>
        
      
    

    
    
    
      <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/leaflet@1.7.1/dist/leaflet.min.css" integrity="" crossorigin="anonymous" media="print" onload="this.media='all'">
    

    

    
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
        <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js" integrity="" crossorigin="anonymous" async></script>
      
    
      
      

      
      

      
    
      
      

      
      

      
    
  

  
  
  
  
  
  <link rel="stylesheet" href="/css/wowchemy.0fb74557ee236a7be4553aea01aad14b.css" />

  




<script async src="https://www.googletagmanager.com/gtag/js?id=G-RM0X76GFY8"></script>
<script>
  window.dataLayer = window.dataLayer || [];

  function gtag() {
      dataLayer.push(arguments);
  }

  function trackOutboundLink(url, target) {
    gtag('event', 'click', {
         'event_category': 'outbound',
         'event_label': url,
         'transport_type': 'beacon',
         'event_callback': function () {
           if (target !== '_blank') {
             document.location = url;
           }
         }
    });
    console.debug("Outbound link clicked: " + url);
  }

  function onClickCallback(event) {
    if ((event.target.tagName !== 'A') || (event.target.host === window.location.host)) {
      return;
    }
    trackOutboundLink(event.target, event.target.getAttribute('target'));  
  }

  gtag('js', new Date());
  gtag('config', 'G-RM0X76GFY8', {});
  gtag('set', {'cookie_flags': 'SameSite=None;Secure'});

  
  document.addEventListener('click', onClickCallback, false);
</script>


  

  

  




  
  
  

  

  
    <link rel="manifest" href="/manifest.webmanifest" />
  

  <link rel="icon" type="image/png" href="/media/icon_hu39dac0accd2519207393463f587ca00e_161255_32x32_fill_lanczos_center_3.png" />
  <link rel="apple-touch-icon" type="image/png" href="/media/icon_hu39dac0accd2519207393463f587ca00e_161255_180x180_fill_lanczos_center_3.png" />

  <link rel="canonical" href="https://hsulab.psy.ntu.edu.tw/publication/content/publication/li-2012/" />

  
  
  
  
  
  
  
  
    
    
  
  

  
  
    
    
  
  <meta property="twitter:card" content="summary" />
  
  <meta property="og:site_name" content="Cognitive Psychometrics Lab" />
  <meta property="og:url" content="https://hsulab.psy.ntu.edu.tw/publication/content/publication/li-2012/" />
  <meta property="og:title" content="Reward prediction errors in reinforcement learning: Psychosis, personality, and modeling issues | Cognitive Psychometrics Lab" />
  <meta property="og:description" content="Making appropriate decisions involves the ability to update information of alternatives from previous experiences. In particular, the updated reward prediction error (RPE) – a discrepancy between the predicted and the actual rewards, is regarded as being encoded by dopamine neurons. Two issues about RPE were discussed in this thesis. First, dysfunction of RPE might link abnormal dopamine systems and therefore the formation of psychotic symptoms (i.e., hallucination and delusion) in schizophrenia (SZ). To examine this hypothesis, we tested SZ patients and healthy controls using a feedback-based “dynamic rewarding task,” in which the subject was required to choose between two different reward options that were alternated in a block fashion. We fit the experimental data with a (standard) reinforcement learning (RL) model using the Bayesian estimation approach. Model-fitting results revealed that SZ patients update their values more rapidly and have more exploratory decisions. We also found that the degree of exploration increases with the severity of the psychotic symptoms. These findings support the hypothesis that abnormal RPE processes correlate with aberrant dopaminergic activities and subjective psychotic experiences. Second, since an individual’s heritable trait might predispose her/his decision-making behavior, we conducted a Tridimensional Personality Questionnaire on subjects to investigate the correlation between personality traits and the estimated parameters in the RL model. Results showed that college students with higher novelty seeking scores have lower value-updating rates, and those with higher reward dependence scores have higher degree of explorations. Moreover, gender differences were found in the task performance. However, no similar patterns were found in SZ patients. Finally, we briefly discussed two modeling issues that are yet to be resolved. The first concerns the negative correlation between the learning rate parameter and the perseveration parameter in the RL model. The second concerns the issue of scale invariance with regard to the perseveration parameter in the RL model. 動物與人在不確定性環境中決策皆需經由試誤學習才能學習到環境的規則，對環境形成預期並依此作為未來決策的依據。根據增強學習理論的假設，預期的更新發生於預期與實際經驗之間有落差時，該落差被稱為酬賞預測誤差（reward prediction error, RPE）。當研究發現多巴胺細胞能夠記錄RPE訊號，RPE在神經科學的研究開始興起。本研究包含兩個議題，分別探討（i）精神分裂症病人（schizophrenia, SZ）的精神病症狀與RPE之關係，（ii）個體在性格上的差異是否影響RPE的處理歷程。首先，有學者認為多巴胺系統異常導致RPE處理錯誤是SZ病人產生精神病症狀（例如：幻覺與妄想）的原因。為檢驗該假設，本研究讓SZ病人進行以兩選項之機率學習的回饋性決策—動態酬賞作業，在作業中得到酬賞機率大的選項每過一段時間會改變，而且該改變不會告知受試者。本研究使用增強學習模型來分析資料，參數估計使用貝氏估計法。研究發現SZ病人更新預期的速度比較快且有較多探索性決策。此外，隨著病人的精神病症狀越嚴重，則會有越多的探索性決策。這些研究結果與假設相符。研究的第二部份分析Cloninger之三向度性格量表各向度得分與動態酬賞作業表現的相關，結果發現一般大學生在動態酬賞作業的表現存在性別差異，而且新奇追求傾向越高者其更新預期的速度越慢，酬賞依賴傾向越高者其探索性決策越多。然而，在SZ病人並無發現類似的結果。另外，本研究也約略討論增強學習模型的參數性質，包括參數間的相關性與單位不變性。" /><meta property="og:image" content="https://hsulab.psy.ntu.edu.tw/media/logo_hu39dac0accd2519207393463f587ca00e_161255_300x300_fit_lanczos_3.png" />
    <meta property="twitter:image" content="https://hsulab.psy.ntu.edu.tw/media/logo_hu39dac0accd2519207393463f587ca00e_161255_300x300_fit_lanczos_3.png" /><meta property="og:locale" content="en-us" />
  
    
      <meta
        property="article:published_time"
        content="2022-04-29T07:51:44&#43;00:00"
      />
    
    <meta property="article:modified_time" content="2012-01-01T00:00:00&#43;00:00">
  

  


    









<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "Article",
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "https://hsulab.psy.ntu.edu.tw/publication/content/publication/li-2012/"
  },
  "headline": "Reward prediction errors in reinforcement learning: Psychosis, personality, and modeling issues",
  
  "datePublished": "2022-04-29T07:51:44Z",
  "dateModified": "2012-01-01T00:00:00Z",
  
  "author": {
    "@type": "Person",
    "name": "Chia-Tzu Li"
  },
  
  "publisher": {
    "@type": "Organization",
    "name": "Cognitive Psychometrics Lab",
    "logo": {
      "@type": "ImageObject",
      "url": "https://hsulab.psy.ntu.edu.tw/media/logo_hu39dac0accd2519207393463f587ca00e_161255_192x192_fit_lanczos_3.png"
    }
  },
  "description": "Making appropriate decisions involves the ability to update information of alternatives from previous experiences. In particular, the updated reward prediction error (RPE) – a discrepancy between the predicted and the actual rewards, is regarded as being encoded by dopamine neurons. Two issues about RPE were discussed in this thesis. First, dysfunction of RPE might link abnormal dopamine systems and therefore the formation of psychotic symptoms (i.e., hallucination and delusion) in schizophrenia (SZ). To examine this hypothesis, we tested SZ patients and healthy controls using a feedback-based “dynamic rewarding task,” in which the subject was required to choose between two different reward options that were alternated in a block fashion. We fit the experimental data with a (standard) reinforcement learning (RL) model using the Bayesian estimation approach. Model-fitting results revealed that SZ patients update their values more rapidly and have more exploratory decisions. We also found that the degree of exploration increases with the severity of the psychotic symptoms. These findings support the hypothesis that abnormal RPE processes correlate with aberrant dopaminergic activities and subjective psychotic experiences. Second, since an individual’s heritable trait might predispose her/his decision-making behavior, we conducted a Tridimensional Personality Questionnaire on subjects to investigate the correlation between personality traits and the estimated parameters in the RL model. Results showed that college students with higher novelty seeking scores have lower value-updating rates, and those with higher reward dependence scores have higher degree of explorations. Moreover, gender differences were found in the task performance. However, no similar patterns were found in SZ patients. Finally, we briefly discussed two modeling issues that are yet to be resolved. The first concerns the negative correlation between the learning rate parameter and the perseveration parameter in the RL model. The second concerns the issue of scale invariance with regard to the perseveration parameter in the RL model. 動物與人在不確定性環境中決策皆需經由試誤學習才能學習到環境的規則，對環境形成預期並依此作為未來決策的依據。根據增強學習理論的假設，預期的更新發生於預期與實際經驗之間有落差時，該落差被稱為酬賞預測誤差（reward prediction error, RPE）。當研究發現多巴胺細胞能夠記錄RPE訊號，RPE在神經科學的研究開始興起。本研究包含兩個議題，分別探討（i）精神分裂症病人（schizophrenia, SZ）的精神病症狀與RPE之關係，（ii）個體在性格上的差異是否影響RPE的處理歷程。首先，有學者認為多巴胺系統異常導致RPE處理錯誤是SZ病人產生精神病症狀（例如：幻覺與妄想）的原因。為檢驗該假設，本研究讓SZ病人進行以兩選項之機率學習的回饋性決策—動態酬賞作業，在作業中得到酬賞機率大的選項每過一段時間會改變，而且該改變不會告知受試者。本研究使用增強學習模型來分析資料，參數估計使用貝氏估計法。研究發現SZ病人更新預期的速度比較快且有較多探索性決策。此外，隨著病人的精神病症狀越嚴重，則會有越多的探索性決策。這些研究結果與假設相符。研究的第二部份分析Cloninger之三向度性格量表各向度得分與動態酬賞作業表現的相關，結果發現一般大學生在動態酬賞作業的表現存在性別差異，而且新奇追求傾向越高者其更新預期的速度越慢，酬賞依賴傾向越高者其探索性決策越多。然而，在SZ病人並無發現類似的結果。另外，本研究也約略討論增強學習模型的參數性質，包括參數間的相關性與單位不變性。"
}
</script>

  

  

  

  





  <title>Reward prediction errors in reinforcement learning: Psychosis, personality, and modeling issues | Cognitive Psychometrics Lab</title>
</head>


<body id="top" data-spy="scroll" data-offset="70" data-target="#TableOfContents" class="page-wrapper   " data-wc-page-id="5de9179fe954fe1967107ed57108c919" >

  
  
  
  
  
  
  
  
  
  <script src="/js/wowchemy-init.min.2da3b1fa37e894630bf6de39b1b694b3.js"></script>

  


<aside class="search-modal" id="search">
  <div class="container">
    <section class="search-header">

      <div class="row no-gutters justify-content-between mb-3">
        <div class="col-6">
          <h1>Search</h1>
        </div>
        <div class="col-6 col-search-close">
          <a class="js-search" href="#" aria-label="Close"><i class="fas fa-times-circle text-muted" aria-hidden="true"></i></a>
        </div>
      </div>

      <div id="search-box">
        
        <input name="q" id="search-query" placeholder="Search..." autocapitalize="off"
        autocomplete="off" autocorrect="off" spellcheck="false" type="search" class="form-control"
        aria-label="Search...">
        
      </div>

      
      

      

    </section>
    <section class="section-search-results">

      <div id="search-hits">
        
      </div>

    </section>
  </div>
</aside>



  <div class="page-header">
    











  


<nav class="navbar navbar-expand-lg navbar-light compensate-for-scrollbar" id="navbar-main">
  <div class="container-xl">

    
    <div class="d-none d-lg-inline-flex">
      <a class="navbar-brand" href="/"><img src="/media/logo_hu39dac0accd2519207393463f587ca00e_161255_0x70_resize_lanczos_3.png" alt="Cognitive Psychometrics Lab"
          
          ></a>
    </div>
    

    
    <button type="button" class="navbar-toggler" data-toggle="collapse"
            data-target="#navbar-content" aria-controls="navbar-content" aria-expanded="false" aria-label="Toggle navigation">
    <span><i class="fas fa-bars"></i></span>
    </button>
    

    
    <div class="navbar-brand-mobile-wrapper d-inline-flex d-lg-none">
      <a class="navbar-brand" href="/"><img src="/media/logo_hu39dac0accd2519207393463f587ca00e_161255_0x70_resize_lanczos_3.png" alt="Cognitive Psychometrics Lab"
        
        ></a>
    </div>
    

    
    
    <div class="navbar-collapse main-menu-item collapse justify-content-start" id="navbar-content">

      
      <ul class="navbar-nav d-md-inline-flex">
        

        

        
        
        
          
        

        

        
        
        
        

        
          
            
            
          
          
            
            
            
              
            
            
          
        

        <li class="nav-item">
          <a class="nav-link " href="/#about"><span>About</span></a>
        </li>

        
        

        

        
        
        

        

        
        
        
        

        
          
            
            
          
          
            
            
            
              
            
            
          
        

        <li class="nav-item">
          <a class="nav-link " href="/#pi"><span>PI</span></a>
        </li>

        
        

        

        
        
        
          
        

        

        
        
        
        

        
          
            
            
          
          
            
            
            
              
            
            
          
        

        <li class="nav-item">
          <a class="nav-link " href="/#members"><span>Members</span></a>
        </li>

        
        

        

        
        
        
          
        

        

        
        
        
        

        
          
            
            
          
          
            
            
            
              
            
            
          
        

        <li class="nav-item">
          <a class="nav-link " href="/#posts"><span>Posts</span></a>
        </li>

        
        

        

        
        
        
          
        

        

        
        
        
        

        
          
            
            
          
          
            
            
            
              
            
            
          
        

        <li class="nav-item">
          <a class="nav-link " href="/#projects"><span>Projects</span></a>
        </li>

        
        

        

        
        
        
          
        

        

        
        
        
        

        
          
            
            
          
          
            
            
            
              
            
            
          
        

        <li class="nav-item">
          <a class="nav-link " href="/#publications"><span>Publications</span></a>
        </li>

        
        

        

        
        
        
          
        

        

        
        
        
        

        
          
            
            
          
          
            
            
            
              
            
            
          
        

        <li class="nav-item">
          <a class="nav-link " href="/#gallery"><span>Gallery</span></a>
        </li>

        
        

        

        
        
        
          
        

        

        
        
        
        

        
          
            
            
          
          
            
            
            
              
            
            
          
        

        <li class="nav-item">
          <a class="nav-link " href="/#join-us"><span>Join Us!</span></a>
        </li>

        
        

        

        
        
        
          
        

        

        
        
        
        

        
          
            
            
          
          
            
            
            
              
            
            
          
        

        <li class="nav-item">
          <a class="nav-link " href="/#contact"><span>Contact</span></a>
        </li>

        
        

      

        
      </ul>
    </div>

    <ul class="nav-icons navbar-nav flex-row ml-auto d-flex pl-md-2">

      
      
        
      

      
      
      <li class="nav-item">
        <a class="nav-link js-search" href="#" aria-label="Search"><i class="fas fa-search" aria-hidden="true"></i></a>
      </li>
      

      
      
      <li class="nav-item dropdown theme-dropdown">
        <a href="#" class="nav-link" data-toggle="dropdown" aria-haspopup="true" aria-label="Display preferences">
          <i class="fas fa-moon" aria-hidden="true"></i>
        </a>
        <div class="dropdown-menu">
          <a href="#" class="dropdown-item js-set-theme-light">
            <span>Light</span>
          </a>
          <a href="#" class="dropdown-item js-set-theme-dark">
            <span>Dark</span>
          </a>
          <a href="#" class="dropdown-item js-set-theme-auto">
            <span>Automatic</span>
          </a>
        </div>
      </li>
      

      
      

    </ul>

  </div>
</nav>


  </div>

  <div class="page-body">
    








<div class="pub">

  












  

  
  
  
<div class="article-container pt-3">
  <h1>Reward prediction errors in reinforcement learning: Psychosis, personality, and modeling issues</h1>

  

  
    


<div class="article-metadata">

  
  
  
  
  <div>
    

  <span >
      <a href="/author/chia-tzu-li/">Chia-Tzu Li</a></span>
  </div>
  
  

  
  <span class="article-date">
    
    
      
    
    January 2012
  </span>
  

  

  

  
  
  
  
  
  

  
  

</div>

    




<div class="btn-links mb-3">
  
  








  
    
  



<a class="btn btn-outline-primary btn-page-header" href="https://hdl.handle.net/11296/4mu57k" target="_blank" rel="noopener">
  PDF
</a>



<a href="#" class="btn btn-outline-primary btn-page-header js-cite-modal"
        data-filename="/publication/content/publication/li-2012/cite.bib">
  Cite
</a>















</div>


  
</div>



  <div class="article-container">

    
    <h3>Abstract</h3>
    <p class="pub-abstract">Making appropriate decisions involves the ability to update information of alternatives from previous experiences. In particular, the updated reward prediction error (RPE) – a discrepancy between the predicted and the actual rewards, is regarded as being encoded by dopamine neurons. Two issues about RPE were discussed in this thesis. First, dysfunction of RPE might link abnormal dopamine systems and therefore the formation of psychotic symptoms (i.e., hallucination and delusion) in schizophrenia (SZ). To examine this hypothesis, we tested SZ patients and healthy controls using a feedback-based “dynamic rewarding task,” in which the subject was required to choose between two different reward options that were alternated in a block fashion. We fit the experimental data with a (standard) reinforcement learning (RL) model using the Bayesian estimation approach. Model-fitting results revealed that SZ patients update their values more rapidly and have more exploratory decisions. We also found that the degree of exploration increases with the severity of the psychotic symptoms. These findings support the hypothesis that abnormal RPE processes correlate with aberrant dopaminergic activities and subjective psychotic experiences. Second, since an individual’s heritable trait might predispose her/his decision-making behavior, we conducted a Tridimensional Personality Questionnaire on subjects to investigate the correlation between personality traits and the estimated parameters in the RL model. Results showed that college students with higher novelty seeking scores have lower value-updating rates, and those with higher reward dependence scores have higher degree of explorations. Moreover, gender differences were found in the task performance. However, no similar patterns were found in SZ patients. Finally, we briefly discussed two modeling issues that are yet to be resolved. The first concerns the negative correlation between the learning rate parameter and the perseveration parameter in the RL model. The second concerns the issue of scale invariance with regard to the perseveration parameter in the RL model. 動物與人在不確定性環境中決策皆需經由試誤學習才能學習到環境的規則，對環境形成預期並依此作為未來決策的依據。根據增強學習理論的假設，預期的更新發生於預期與實際經驗之間有落差時，該落差被稱為酬賞預測誤差（reward prediction error, RPE）。當研究發現多巴胺細胞能夠記錄RPE訊號，RPE在神經科學的研究開始興起。本研究包含兩個議題，分別探討（i）精神分裂症病人（schizophrenia, SZ）的精神病症狀與RPE之關係，（ii）個體在性格上的差異是否影響RPE的處理歷程。首先，有學者認為多巴胺系統異常導致RPE處理錯誤是SZ病人產生精神病症狀（例如：幻覺與妄想）的原因。為檢驗該假設，本研究讓SZ病人進行以兩選項之機率學習的回饋性決策—動態酬賞作業，在作業中得到酬賞機率大的選項每過一段時間會改變，而且該改變不會告知受試者。本研究使用增強學習模型來分析資料，參數估計使用貝氏估計法。研究發現SZ病人更新預期的速度比較快且有較多探索性決策。此外，隨著病人的精神病症狀越嚴重，則會有越多的探索性決策。這些研究結果與假設相符。研究的第二部份分析Cloninger之三向度性格量表各向度得分與動態酬賞作業表現的相關，結果發現一般大學生在動態酬賞作業的表現存在性別差異，而且新奇追求傾向越高者其更新預期的速度越慢，酬賞依賴傾向越高者其探索性決策越多。然而，在SZ病人並無發現類似的結果。另外，本研究也約略討論增強學習模型的參數性質，包括參數間的相關性與單位不變性。</p>
    

    
    
    <div class="row">
      <div class="col-md-1"></div>
      <div class="col-md-10">
        <div class="row">
          <div class="col-12 col-md-3 pub-row-heading">Type</div>
          <div class="col-12 col-md-9">
            <a href="/publication/#7">
              Thesis
            </a>
          </div>
        </div>
      </div>
      <div class="col-md-1"></div>
    </div>
    <div class="d-md-none space-below"></div>
    

    

    <div class="space-below"></div>

    <div class="article-style"></div>

    






<div class="article-tags">
  
  <a class="badge badge-light" href="/tag/bayesian-estimation/">Bayesian estimation</a>
  
  <a class="badge badge-light" href="/tag/psychosis/">psychosis</a>
  
  <a class="badge badge-light" href="/tag/reinforcement-learning-model/">reinforcement learning model</a>
  
  <a class="badge badge-light" href="/tag/reward-prediction-error/">reward prediction error</a>
  
  <a class="badge badge-light" href="/tag/schizophrenia/">schizophrenia</a>
  
  <a class="badge badge-light" href="/tag/tridimensional-personality-questionnaire/">Tridimensional Personality Questionnaire</a>
  
</div>



<div class="share-box">
  <ul class="share">
    
      
      
      
        
      
      
      
      <li>
        <a href="https://twitter.com/intent/tweet?url=https://hsulab.psy.ntu.edu.tw/publication/content/publication/li-2012/&amp;text=Reward%20prediction%20errors%20in%20reinforcement%20learning:%20Psychosis,%20personality,%20and%20modeling%20issues" target="_blank" rel="noopener" class="share-btn-twitter" aria-label="twitter">
          <i class="fab fa-twitter"></i>
        </a>
      </li>
    
      
      
      
        
      
      
      
      <li>
        <a href="https://www.facebook.com/sharer.php?u=https://hsulab.psy.ntu.edu.tw/publication/content/publication/li-2012/&amp;t=Reward%20prediction%20errors%20in%20reinforcement%20learning:%20Psychosis,%20personality,%20and%20modeling%20issues" target="_blank" rel="noopener" class="share-btn-facebook" aria-label="facebook">
          <i class="fab fa-facebook"></i>
        </a>
      </li>
    
      
      
      
        
      
      
      
      <li>
        <a href="mailto:?subject=Reward%20prediction%20errors%20in%20reinforcement%20learning:%20Psychosis,%20personality,%20and%20modeling%20issues&amp;body=https://hsulab.psy.ntu.edu.tw/publication/content/publication/li-2012/" target="_blank" rel="noopener" class="share-btn-email" aria-label="envelope">
          <i class="fas fa-envelope"></i>
        </a>
      </li>
    
      
      
      
        
      
      
      
      <li>
        <a href="https://www.linkedin.com/shareArticle?url=https://hsulab.psy.ntu.edu.tw/publication/content/publication/li-2012/&amp;title=Reward%20prediction%20errors%20in%20reinforcement%20learning:%20Psychosis,%20personality,%20and%20modeling%20issues" target="_blank" rel="noopener" class="share-btn-linkedin" aria-label="linkedin-in">
          <i class="fab fa-linkedin-in"></i>
        </a>
      </li>
    
  </ul>
</div>











  
  
    




  














  
  
  <div class="article-widget content-widget-hr">
    <h3>Related</h3>
    <ul>
      
      <li><a href="/publication/li-2012/">Reward prediction errors in reinforcement learning: Psychosis, personality, and modeling issues</a></li>
      
      <li><a href="/publication/content/publication/liu-2018/">Affective influences on reward-based decision making</a></li>
      
      <li><a href="/publication/content/publication/chen-2012/">Akt1 deficiency modulates reward learning and reward prediction error in mice</a></li>
      
      <li><a href="/publication/content/publication/liu-2017/">Misfortune may be a blessing in disguise: Fairness perception and emotion modulate decision making</a></li>
      
      <li><a href="/publication/liu-2018/">Affective influences on reward-based decision making</a></li>
      
    </ul>
  </div>
  





  </div>
</div>
  </div>

  <div class="page-footer">
    
    
    <div class="container">
      <footer class="site-footer">

  



  

  

  
  <p class="powered-by">
    Copyright © 2021-2023 Cognitive Psychometrics Lab. All rights reserved.
  </p>
  

  
  






  <p class="powered-by">
    
    
    
      
      
      
      
      
      
      Published with <a href="https://wowchemy.com/?utm_campaign=poweredby" target="_blank" rel="noopener">Wowchemy</a> — the free, <a href="https://github.com/wowchemy/wowchemy-hugo-themes" target="_blank" rel="noopener">open source</a> website builder that empowers creators.
    
  </p>
</footer>

    </div>
    
  </div>

  
<div id="modal" class="modal fade" role="dialog">
  <div class="modal-dialog">
    <div class="modal-content">
      <div class="modal-header">
        <h5 class="modal-title">Cite</h5>
        <button type="button" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body">
        <pre><code class="tex hljs"></code></pre>
      </div>
      <div class="modal-footer">
        <a class="btn btn-outline-primary my-1 js-copy-cite" href="#" target="_blank">
          <i class="fas fa-copy"></i> Copy
        </a>
        <a class="btn btn-outline-primary my-1 js-download-cite" href="#" target="_blank">
          <i class="fas fa-download"></i> Download
        </a>
        <div id="modal-error"></div>
      </div>
    </div>
  </div>
</div>

      

    
    <script src="/js/vendor-bundle.min.b73dfaac3b6499dc997741748a7c3fe2.js"></script>

    
    
    
      
      
        <script src="https://cdn.jsdelivr.net/gh/desandro/imagesloaded@v4.1.4/imagesloaded.pkgd.min.js" integrity="sha512-S5PZ9GxJZO16tT9r3WJp/Safn31eu8uWrzglMahDT4dsmgqWonRY9grk3j+3tfuPr9WJNsfooOR7Gi7HL5W2jw==" crossorigin="anonymous"></script>
        <script src="https://cdn.jsdelivr.net/gh/metafizzy/isotope@v3.0.6/dist/isotope.pkgd.min.js" integrity="sha512-Zq2BOxyhvnRFXu0+WE6ojpZLOU2jdnqbrM1hmVdGzyeCa1DgM3X5Q4A/Is9xA1IkbUeDd7755dNNI/PzSf2Pew==" crossorigin="anonymous"></script>
      

      
      

      
        <script src="https://cdn.jsdelivr.net/gh/mermaid-js/mermaid@v8.8.4/dist/mermaid.min.js" integrity="sha512-+TNmhaRJf3jyYHTpzEq/5I6b+aGyhzWb21mGdHAjxSGSYwxN9Grug3Y3B9qVxWfKKY8MscE/6mr9walWvFLFvQ==" crossorigin="anonymous" title="mermaid"></script>
      

      
        
        <script src="https://cdn.jsdelivr.net/gh/highlightjs/cdn-release@10.2.1/build/highlight.min.js" integrity="sha512-Ypjm0o7jOxAd4hpdoppSEN0TQOC19UtPAqD+4s5AlXmUvbmmS/YMxYqAqarQYyxTnB6/rqip9qcxlNB/3U9Wdg==" crossorigin="anonymous"></script>
        
        
        <script src="https://cdn.jsdelivr.net/gh/highlightjs/cdn-release@10.2.1/build/languages/r.min.js" crossorigin="anonymous"></script>
        
        <script src="https://cdn.jsdelivr.net/gh/highlightjs/cdn-release@10.2.1/build/languages/python.min.js" crossorigin="anonymous"></script>
        
        <script src="https://cdn.jsdelivr.net/gh/highlightjs/cdn-release@10.2.1/build/languages/latex.min.js" crossorigin="anonymous"></script>
        
      

    

    
    
    
      <script src="https://cdn.jsdelivr.net/npm/leaflet@1.7.1/dist/leaflet.min.js" integrity="" crossorigin="anonymous"></script>
    

    
    

    
    
    
      
      <script id="search-hit-fuse-template" type="text/x-template">
        <div class="search-hit" id="summary-{{key}}">
          <div class="search-hit-content">
            <div class="search-hit-name">
              <a href="{{relpermalink}}">{{title}}</a>
              <div class="article-metadata search-hit-type">{{type}}</div>
              <p class="search-hit-description">{{snippet}}</p>
            </div>
          </div>
        </div>
      </script>
      
        <script src="https://cdn.jsdelivr.net/gh/krisk/Fuse@v3.2.1/dist/fuse.min.js" integrity="sha512-o38bmzBGX+hD3JHWUFCDA09btWaqrNmoJ3RXLlrysA7PP01Kgs4UlE4MhelE1v5dJR3+cxlR4qQlotsW7jKsnw==" crossorigin="anonymous"></script>
        <script src="https://cdn.jsdelivr.net/gh/julmot/mark.js@8.11.1/dist/jquery.mark.min.js" integrity="sha512-mhbv5DqBMgrWL+32MmsDOt/OAvqr/cHimk6B8y/bx/xS88MVkYGPiVv2ixKVrkywF2qHplNRUvFsAHUdxZ3Krg==" crossorigin="anonymous"></script>
      
    

    
    

    
    
    
    

    
    
      
      
      
      
      
      
      
    

    
    
    
    
    
    
    
    
      
      
    
    
    <script src="/en/js/wowchemy.min.7cd6ec29d281a73c92a2958a1584aadc.js"></script>

    
  <script async defer src="https://buttons.github.io/buttons.js"></script>




</body>
</html>
